{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div align=\"right\">Enseignant : Aric Wizenberg</div>\n",
    "<div align=\"right\">E-mail : icarwiz@yahoo.fr</div>\n",
    "<div align=\"right\">Année : 2018/2019</div><br><br><br>\n",
    "<div align=\"center\"><span style=\"font-family:Lucida Caligraphy;font-size:32px;color:darkgreen\">Master 2 MASERATI - Cours de Python</span></div><br><br>\n",
    "<div align=\"center\"><span style=\"font-family:Lucida Caligraphy;font-size:24px;color:#e60000\">Traitement de données</span></div><br><br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargeons d'abord les modules ainsi qu'un jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:13:45.481074Z",
     "start_time": "2019-01-11T13:13:43.763188Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:13:49.863311Z",
     "start_time": "2019-01-11T13:13:49.748333Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gflight = pd.read_csv('../data/Googleflights.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jettons un coup d'oeil à la table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:13:53.562987Z",
     "start_time": "2019-01-11T13:13:53.530045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>respid</th>\n",
       "      <th>extrtime</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>company</th>\n",
       "      <th>depdate</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>duration</th>\n",
       "      <th>flighttype</th>\n",
       "      <th>price</th>\n",
       "      <th>stopover</th>\n",
       "      <th>stopovertime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15/01/2016 10:12:52</td>\n",
       "      <td>SXB</td>\n",
       "      <td>NTE</td>\n",
       "      <td>HOP!</td>\n",
       "      <td>2016-03-15T14:50:00</td>\n",
       "      <td>2016-03-15T16:15:00</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>aller simple</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Sans escale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>15/01/2016 10:12:46</td>\n",
       "      <td>MRS</td>\n",
       "      <td>NTE</td>\n",
       "      <td>Air France-Air France</td>\n",
       "      <td>2016-03-15T20:00:00</td>\n",
       "      <td>2016-03-16T10:30:00</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>aller simple</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1 escale</td>\n",
       "      <td>12h 00min à ORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>15/01/2016 10:18:56</td>\n",
       "      <td>LRT</td>\n",
       "      <td>NCE</td>\n",
       "      <td>Air France-Air France</td>\n",
       "      <td>2016-03-15T18:00:00</td>\n",
       "      <td>2016-03-16T14:40:00</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>aller simple</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1 escale</td>\n",
       "      <td>17h 45min à CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>33</td>\n",
       "      <td>55</td>\n",
       "      <td>15/01/2016 10:15:33</td>\n",
       "      <td>ORY</td>\n",
       "      <td>RNS</td>\n",
       "      <td>Air France-HOP!</td>\n",
       "      <td>2016-03-15T09:55:00</td>\n",
       "      <td>2016-03-16T09:30:00</td>\n",
       "      <td>23.583333</td>\n",
       "      <td>aller simple</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1 escale</td>\n",
       "      <td>21h 15min à TLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>15/01/2016 10:19:24</td>\n",
       "      <td>UIP</td>\n",
       "      <td>MRS</td>\n",
       "      <td>Air France-Air France</td>\n",
       "      <td>2016-03-15T18:15:00</td>\n",
       "      <td>2016-03-15T21:55:00</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>aller simple</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1 escale</td>\n",
       "      <td>55min à ORY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  respid             extrtime origin destination  \\\n",
       "693    6       2  15/01/2016 10:12:52    SXB         NTE   \n",
       "626    5      79  15/01/2016 10:12:46    MRS         NTE   \n",
       "5792  67      54  15/01/2016 10:18:56    LRT         NCE   \n",
       "2822  33      55  15/01/2016 10:15:33    ORY         RNS   \n",
       "5913  72       3  15/01/2016 10:19:24    UIP         MRS   \n",
       "\n",
       "                    company              depdate              arrdate  \\\n",
       "693                    HOP!  2016-03-15T14:50:00  2016-03-15T16:15:00   \n",
       "626   Air France-Air France  2016-03-15T20:00:00  2016-03-16T10:30:00   \n",
       "5792  Air France-Air France  2016-03-15T18:00:00  2016-03-16T14:40:00   \n",
       "2822        Air France-HOP!  2016-03-15T09:55:00  2016-03-16T09:30:00   \n",
       "5913  Air France-Air France  2016-03-15T18:15:00  2016-03-15T21:55:00   \n",
       "\n",
       "       duration    flighttype  price     stopover     stopovertime  \n",
       "693    1.416667  aller simple   61.0  Sans escale              NaN  \n",
       "626   14.500000  aller simple  107.0     1 escale  12h 00min à ORY  \n",
       "5792  20.666667  aller simple  172.0     1 escale  17h 45min à CDG  \n",
       "2822  23.583333  aller simple  129.0     1 escale  21h 15min à TLS  \n",
       "5913   3.666667  aller simple   86.0     1 escale      55min à ORY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gflight.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:14:12.688376Z",
     "start_time": "2019-01-11T13:14:12.674468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6815 entries, 0 to 6814\n",
      "Data columns (total 13 columns):\n",
      "id              6815 non-null int64\n",
      "respid          6815 non-null int64\n",
      "extrtime        6815 non-null object\n",
      "origin          6815 non-null object\n",
      "destination     6815 non-null object\n",
      "company         6815 non-null object\n",
      "depdate         6815 non-null object\n",
      "arrdate         6815 non-null object\n",
      "duration        6813 non-null float64\n",
      "flighttype      6815 non-null object\n",
      "price           6805 non-null float64\n",
      "stopover        6815 non-null object\n",
      "stopovertime    6672 non-null object\n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 692.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_gflight.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaines de caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifier une série de manière systématique grâce à map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur la base d'un dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode **Series.map()** permet, en utilisant un dictionnaire de \"correspondance\" de convertir des modalités en d'autres modalités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:15:39.133457Z",
     "start_time": "2019-01-11T13:15:39.126478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sans escale', '1 escale'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gflight['stopover'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:15:44.172071Z",
     "start_time": "2019-01-11T13:15:44.168044Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_escales = {\n",
    "    'Sans escale' : 0,\n",
    "    '1 escale' : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:19:30.392767Z",
     "start_time": "2019-01-11T13:19:30.383791Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gflight['stopover'] = df_gflight['stopover'].map(dict_escales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:19:33.001411Z",
     "start_time": "2019-01-11T13:19:32.995428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5559    1\n",
       "2039    1\n",
       "6441    1\n",
       "4956    1\n",
       "5335    1\n",
       "Name: stopover, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gflight['stopover'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur la base d'une fonction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode **Series.map()** permet aussi d'appliquer une fonction à chaque élément d'une Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:20:00.773622Z",
     "start_time": "2019-01-11T13:20:00.767639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '45min à LYS', '1h 40min à LYS', ..., '21h 55min à MRS',\n",
       "       '11h 50min à MRS', '23h 50min à NCE'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gflight['stopovertime'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut par exemple appliquer la fonction suivante pour transformer nos ids en chaines de caractères en index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:39:13.691517Z",
     "start_time": "2019-01-11T13:39:13.685530Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_func(val):\n",
    "    if val is np.nan:\n",
    "        return np.nan\n",
    "    else:\n",
    "        if 'h ' in val:\n",
    "            heures = int(val.split('h ')[0]) #Decoupe selon 'h ' et après le convertir en entier.\n",
    "            minutes = int(val.split('h ')[1].split('min')[0]) #Decoupe en plus selon 'Min' maintenant.\n",
    "            return heures + minutes/60\n",
    "        elif 'min' in val:\n",
    "            return int(val.split('min')[0])/60\n",
    "        else:\n",
    "            raise BaseException('Problème')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:39:15.537534Z",
     "start_time": "2019-01-11T13:39:15.513564Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gflight['stop_time'] = df_gflight['stopovertime'].map(conv_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:39:17.102103Z",
     "start_time": "2019-01-11T13:39:17.093130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopovertime</th>\n",
       "      <th>stop_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>8h 05min à CDG</td>\n",
       "      <td>8.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>11h 55min à AMS</td>\n",
       "      <td>11.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>6h 50min à ORY</td>\n",
       "      <td>6.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>12h 50min à ORY</td>\n",
       "      <td>12.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>10h 55min à ORY</td>\n",
       "      <td>10.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stopovertime  stop_time\n",
       "1672   8h 05min à CDG   8.083333\n",
       "3902  11h 55min à AMS  11.916667\n",
       "401    6h 50min à ORY   6.833333\n",
       "4928  12h 50min à ORY  12.833333\n",
       "2639  10h 55min à ORY  10.916667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gflight[['stopovertime', 'stop_time']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire de même pour extraire les aéroports de correspondance. Ici, c'est une fonction lambda qui est utilisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:41:29.052477Z",
     "start_time": "2019-01-11T13:41:29.048488Z"
    }
   },
   "outputs": [],
   "source": [
    "def ma_fonc(x):\n",
    "    if x is np.nan:\n",
    "        return ''\n",
    "    else:\n",
    "        return x.split(' à ')[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:39:32.125451Z",
     "start_time": "2019-01-11T13:39:32.114482Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gflight['stop_place'] = df_gflight['stopovertime'].map(lambda x: '' if x is np.nan else x.split(' à ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T13:39:33.545855Z",
     "start_time": "2019-01-11T13:39:33.533887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopovertime</th>\n",
       "      <th>stop_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>9h 25min à ORY</td>\n",
       "      <td>ORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>7h 50min à CDG</td>\n",
       "      <td>CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>26h 00min à CDG</td>\n",
       "      <td>CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>23h 25min à ORY</td>\n",
       "      <td>ORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>22h 15min à ORY</td>\n",
       "      <td>ORY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stopovertime stop_place\n",
       "1506   9h 25min à ORY        ORY\n",
       "5384   7h 50min à CDG        CDG\n",
       "5947  26h 00min à CDG        CDG\n",
       "1469  23h 25min à ORY        ORY\n",
       "2404  22h 15min à ORY        ORY"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gflight[['stopovertime', 'stop_place']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Pour aller plus loin :</b> <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.map.html> Doc officielle Pandas sur la <b>méthode map</b></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objet .str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre manière aurait été de prendre les 3 derniers caractères de la chaine de caractères, pour faire des opérations de type méthode de **str** sur une Serie **object**, on peut utiliser l'objet **.str**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['stopovertime'].str[-3:].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des méthodes aprises dans le cadre des chaines de caractères peuvent être utilisées avec l'objet **.str** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['stopovertime'].str.split().sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gflight['stopovertime'].str.upper().sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pour aller plus loin:</b> <a href=https://pandas.pydata.org/pandas-docs/stable/text.html> Tutoriel sur le <b>traitement de chaines de caractères </b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque :\n",
    "\n",
    "les **object** et **floatXX** contenir des **numpy.nan** (**valeur manquante** dans une **numpy.ndarray**, et par héritage **pandas.Series** et **pandas.DataFrame**), pas les **intXX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Savoir quelles cases sont nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou l'inverse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.notnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut les compter ainsi (car True est considéré = 1 et False = 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supprimer les lignes où il y a des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est typiquement ce qu'on voudra faire avec les valeurs manquantes sur notre variable expliquée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight = df_gflight.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialiser les valeurs manquantes d'une variable explicative à la valeur moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['duration'] = df_gflight['duration'].fillna(df_gflight['duration'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialiser les valeurs manquantes d'une variable explicative à une modalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['stop_time'] = df_gflight['stop_time'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gflight.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pour aller plus loin:</b> <a href=https://pandas.pydata.org/pandas-docs/stable/missing_data.html> Tutoriel sur le <b>traitement des valeurs manquantes</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout/suppression de colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajouter une colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutons la Series représentant le temps en vol, qui est la différence entre la durée totale et le temps en correspondance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['inflight'] = df_gflight['duration'] - df_gflight['stop_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supprimer une colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'il y a des Series avec une seule modalité, elles sont généralement inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gflight['flighttype'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profitons-en pour supprimer quelques Series inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight = df_gflight.drop(['flighttype', 'stopovertime', 'id', 'respid', 'extrtime'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**axis=1** car on veut supprimer des colonnes et que l'axe 0, ce sont les lignes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séries temporelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion en format date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables temporelles en format texte sont aussi très difficiles à exploiter. On va **a minima** les transformer en objet **Timestamp** (l'objet de la librairie pandas permettant de donner une valeur temporelle précise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in ['depdate', 'arrdate']:\n",
    "    df_gflight[elem] = pd.to_datetime(df_gflight[elem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalement, to_datetime() fonctionne bien (surtout quand on lui demande de travailler sur un grand nombre de cas possibles, car il a alors moins de chance de se tromper en déterminant automatiquement un format de date/heure)\n",
    "\n",
    "Mais on peut le forcer à adopter un format précis pour éviter toute erreur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df_gflight['depdate'], format='%Y-%m-%dT%H:%M:%S').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion en float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le format de séries temporelles que nous avons utilisé ne va pas nous convenir pour les régressions et les algotithmes de Data Science (il nous... On peut ajouter des colonnes calculant des timedelta, un nombre d'unité de temps (des jours par exemple, **D**) depuis une date de référence. Une bonne idée peut être de prendre la plus ancienne des dates des colonnes concernées..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_gflight['depdate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_gflight['depdate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['time'] = (df_gflight['depdate'] - df_gflight['depdate'].min()) / np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Pour aller plus loin :</b> <a href=https://docs.scipy.org/doc/numpy/reference/arrays.datetime.html> Doc officielle Numpy sur les <b>objets datetime</b></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objet .dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les Series de chaines de caractères, pour lesquelles il existe un objet **.str**, pour les Series de dates, il existe un objet **.dt** qui permet de faire appel aux méthode des objets **datetime.datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['depdate'].dt.hour.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['depdate'].dt.dayofweek.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gflight['depdate'].dt.time.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pour aller plus loin:</b> <a href=https://pandas.pydata.org/pandas-docs/stable/timeseries.html> Tutoriel sur le <b>traitement des séries temporelles</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object ou Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Généralement, on essaie de faire en sorte d'avoir le moins de colonnes de type **object** (**str**) dans nos DataFrame, c'est le type que pandas assigne par défaut aux données qui ont l'air d'être des chaines de caractères.\n",
    "\n",
    "Ce type pose deux problèmes:\n",
    "- Il prend beaucoup de place en mémoire\n",
    "- Il est le plus difficile à traiter dans le cadre de l'analyse\n",
    "\n",
    "Et c'est rare qu'une colonne ait de bonnes raisons d'être de ce type (à part les trucs du genre colonne de commentaires). On va généralement convertir le plus de colonnes possible en types standardisés, plus faciles à exploiter ou retransformer\n",
    "\n",
    "A l'inverse, dans les Data Science, on aime les nombres à virgule, les **float** qui sont utilisables par les algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générer des catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut convertir les colonnes en utilisant la méthode **pandas.Series.astype('category')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in ['origin', 'destination', 'stopover', 'company', 'stop_place']:\n",
    "    df_gflight[elem] = df_gflight[elem].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objet .cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même que les chaines de caractères ont **.str** et les dates ont **.dt**, les catégories ont **.cat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['origin'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['origin'].cat.codes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight['origin'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Pour aller plus loin:</b> <a href=https://pandas.pydata.org/pandas-docs/stable/categorical.html> Tutoriel sur le <b>traitement des catégories</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de variables muettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables catégorielles posent encore plus de problèmes, auxquels on peut apporter plusieurs solutions:\n",
    "- transformer les variables en dummies à deux modalités en choix 0 / 1\n",
    "- transformer les variables multimodales :\n",
    "    - soit en équivalent numérique si ça a un sens, si l'on pense que la distance numérique entre deux modalités correspond à ce que l'on au modélise... (par exemple : 1, 2 ou 3 chambres ? Est-ce que la distance entre 1 et 2 chambres est bien égale à la distance entre 2 et 3 chambres? Souvent ce ne sera pas un bon choix en termes de modèle)\n",
    "    - soit en une série de variables oui / non (souvent un meilleur choix lorsque l'on peut se permettre de perdre le nombre de degrés de liberté correspondant au nombre de modalités - 1), en retirant toujours une modalité de référence\n",
    "    - soit en une valeur numérique \"représentant\" la modalité (centre de gravité ou autre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une solution est de générer automatiquement des dummies à partir de catégories de type chaine de caractère en utilisant la fonction **pandas.get_dummies(series)** (**conseil :** utilisez-là avec l'option **drop_first=True** ou supprimez manuelement la serie qui servira de référence, pour éviter d'avoir un problème de **multicolinéarité parfaite** lors d'une régression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df_gflight['destination'], drop_first=True)\n",
    "df_dummies.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:58:46.817404Z",
     "start_time": "2018-09-12T19:58:46.806404Z"
    }
   },
   "source": [
    "On peut ensuite ajouter ces nouvelles variables en faisant une concaténation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecriture dans un fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stockons cette base de données modifiée, sous format Excel (pour visualiser facilement les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.to_excel('../output/Output_GFLT.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sous format **Pickle** (le format pure Python) juste pour pouvoir récupérer les données dans un autre notebook à **100% identique au DataFrame que nous avons ici**.\n",
    "\n",
    "Les **catégories** en particulier sont un type qu'Excel ne sait pas gérer contrairement à Python... On perdrait donc cela en rechargeant depuis le fichier Excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.to_pickle('../output/Output_GFLT.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointures et concatenations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concaténation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut facilement ajouter des lignes à un DataFrame en utilisant la fonction **pandas.concat()**. \n",
    "\n",
    "Elle prend comme seul argument obligatoire un **tuple** ou une **list** de **DataFrame** (on peut en concatener plusieurs d'un coup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight_avec_dummies = pd.concat([df_gflight, df_dummies], axis=1)\n",
    "\n",
    "df_gflight_avec_dummies.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, ici il faut concatener des DataFrame dans le sens des colonnes, pas dans le sens des lignes, il faut alors spécifier le paramètre **axis=1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Pour aller plus loin :</b> <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html> Doc officielle sur la méthode <b> .concat()</b></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jointure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aero = pd.read_csv('../data/airports.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_aero) == len(df_aero['Code'].unique())\n",
    "df_aero = df_aero.set_index('Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gflight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(\n",
    "    df_gflight, # table de gauche\n",
    "    df_aero[['Name']], # table de droite\n",
    "    how='inner', # mode de jointure : inner, outer, left, right\n",
    "    left_on='origin', # colonne utilisée pour la jointure dans la table de gauche\n",
    "    right_index=True,  # au lieu d'une colonne on utilise l'index de la table de droite\n",
    ")\n",
    "# on utilise le paramètre on='col_name' lorsque le nom de colonne est le même\n",
    "# dans les deux dataframe, dans ce cas, ça remplace les paramètres\n",
    "# left_on, right_on, left_index, right_index\n",
    "\n",
    "new_df = new_df.rename({'Name': 'name_orig'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(\n",
    "    new_df,\n",
    "    df_aero[['Name']],\n",
    "    how='inner',\n",
    "    left_on='destination',\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "new_df = new_df.rename({'Name': 'name_dest'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(new_df) == len(df_gflight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.sample(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Pour aller plus loin :</b> <a href=https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html> Doc officielle sur la méthode <b>.merge()</b></a></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Pour aller plus loin :</b> <a href=https://pandas.pydata.org/pandas-docs/stable/merging.html>Tutoriel sur les <b> jointures et concatenations </b></a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "500px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "660px",
    "left": "0px",
    "right": "1359px",
    "top": "107px",
    "width": "187px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
