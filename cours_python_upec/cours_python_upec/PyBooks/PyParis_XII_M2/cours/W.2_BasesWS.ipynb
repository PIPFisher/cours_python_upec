{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<br>\n", "<div align=\"right\">Enseignant : Aric Wizenberg</div>\n", "<div align=\"right\">E-mail : icarwiz@yahoo.fr</div>\n", "<div align=\"right\">Ann\u00e9e : 2018/2019</div><br><br><br>\n", "<div align=\"center\"><span style=\"font-family:Lucida Caligraphy;font-size:32px;color:darkgreen\">Master 2 MASERATI - Cours de Python</span></div><br><br>\n", "<div align=\"center\"><span style=\"font-family:Lucida Caligraphy;font-size:24px;color:#e60000\">Bases du webscraping</span></div><br><br>\n", "<hr>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Quelques d\u00e9finitions maison"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Web-crawling** : le fait de parcourir l'arborescence d'un site web pour en r\u00e9cup\u00e9rer des informations, \u00e0 la base utilis\u00e9 pour obtenir des arborescences de page\n", "\n", "**Data-scraping** : le fait de parcourir une structure complexe pour en r\u00e9cup\u00e9rer des informations, pas n\u00e9cessairement sur le web d'ailleurs, et de les transformant d'une structure de donn\u00e9es difficilement exploitable \u00e0 une structure de donn\u00e9es simple \u00e0 exploiter (une ou des tables de donn\u00e9es en g\u00e9n\u00e9ral)\n", "\n", "**Bot** (abbr\u00e9viation de robot) : logiciel ayant pour objectif de faire une t\u00e2che r\u00e9p\u00e9titive qu'un \u00eatre humain pourrait faire.\n", "\n", "**Scraper** : **Bot** programm\u00e9 pour \u00e9ffectuer une activit\u00e9 de data-scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Le web-scraping** est une activit\u00e9 consistant \u00e0 r\u00e9cup\u00e9rer de mani\u00e8re automatis\u00e9e des donn\u00e9es depuis un site web et \u00e0 les transformer en donn\u00e9es structur\u00e9es facilement exploitables"]}, {"cell_type": "markdown", "metadata": {}, "source": ["J'ai crois\u00e9 le mot web-screening... Je ne vois pas bien quelle est la diff\u00e9rence avec le web-scraping."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Soft et hard-scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["On peut diviser l'activit\u00e9 d'un programmeur de scraper en deux cat\u00e9gories que personnelement, je nomme **soft-scraping** et **hard-scraping** (NB : ce sont mes propres termes, ils ne sont pas officiels)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Soft-scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Le **soft-scraping** consiste \u00e0 r\u00e9cup\u00e9rer de la donn\u00e9e depuis un site web **qui organise officiellement la fourniture de donn\u00e9es \u00e0 travers un point d'entr\u00e9e d\u00e9di\u00e9** : une **API** (Application Programming Interface).\n", "\n", "Une **API** est un ensemble d'outils mis \u00e0 disposition des programmeurs externes au site pour qu'ils puissent obtenir rapidement, et dans un cadre organis\u00e9, des donn\u00e9es depuis ce site.\n", "\n", "Cette activit\u00e9 **ne pose jamais de probl\u00e8me en termes de l\u00e9galit\u00e9**, le scraping se fait **en accord** avec le site dont vous essayez d'obtenir des donn\u00e9es, et dans un cadre (impliquant g\u00e9n\u00e9ralement la cr\u00e9ation d'un compte utilisateur), et \u00e0 des conditions qu'il fixe lui-m\u00eame (limite de nombre de requ\u00eates par p\u00e9riode de temps)\n", "\n", "C'est une activit\u00e9 **plut\u00f4t facile \u00e0 mettre en oeuvre**, et **bien document\u00e9e** (gr\u00e2ce \u00e0 la documentation de l'API du site concern\u00e9)\n", "\n", "**Il faut bien s\u00fbr toujours v\u00e9rifier qu'il n'existe pas une solution de soft-scraping accessible avant de se lancer dans du hard-scraping**... Pour cela il suffit g\u00e9n\u00e9ralement de faire une recherche sur Google du type : **API nom_du_site** (par exemple : \"API Twitter\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il faut toujours commencer par v\u00e9rifier qu'un site ne met pas \u00e0 disposition des d\u00e9veloppeurs une API.\n", "\n", "Il existe \u00e9norm\u00e9ment de sites d'API, en voici quelques uns : \n", "- [Google](https://developers.google.com/products/) qui en a plusieurs proposant des services distincts, par exemple [l'API Google Maps](https://developers.google.com/maps/)\n", "- [Wikipedia](https://www.mediawiki.org/wiki/API:Main_page/fr), qui est h\u00e9las un peu limit\u00e9e, les donn\u00e9es d'infobox ne sont par exemple que faiblement format\u00e9es\n", "- [Data.gouv.fr](https://www.data.gouv.fr/fr/apidoc/), l'Open Data du gouvernement\n", "- [OCDE](https://data.oecd.org/api/sdmx-json-documentation/) ou [FMI](http://datahelp.imf.org/knowledgebase/articles/667681-json-restful-web-service), des sites pour obtenir des donn\u00e9es macro-\u00e9conomiques \u00e0 travers la norme SDMX\n", "- [Twitter](https://developer.twitter.com/en/docs/) et [Facebook](https://developers.facebook.com/)\n", "- [Spotify](https://developer.spotify.com/web-api/) ou [Deezer](http://developers.deezer.com/api), des sites pour obtenir des donn\u00e9es musicales\n", "- [IMDb](http://imdbapi.net/) ou [OMDb](https://www.omdbapi.com/), des sites pour obtenir des donn\u00e9es en lien avec des films\n", "- [Quandl](https://www.quandl.com/tools/api) ou [Alpha Vantage](https://www.alphavantage.co/documentation/), des sites pour obtenir des donn\u00e9es financi\u00e8res\n", "- [Football Data](https://api.football-data.org/docs/v1/index.html) ou [Sports Open Data](http://sportsopendata.net/api-console/), des sites pour obtenir des donn\u00e9es sportives\n", "- [SNCF](https://www.digital.sncf.com/startup/api) ou [RATP](https://data.ratp.fr/api/v1/documentation), des sites pour obtenir des donn\u00e9es li\u00e9es aux transports\n", "\n", "Les API ont des avantages certains :\n", "- Aucun probl\u00e8me de l\u00e9galit\u00e9 de leur utilisation (attention tout de m\u00eame les API ont des conditions d'utilisation, certaines refusent une r\u00e9utilisation \u00e0 des fins commerciaux...)\n", "- Une documentation et une communaut\u00e9 d'utilisateurs g\u00e9n\u00e9rant de la documentation suppl\u00e9mentaire au travers des forums\n", "- Un fonctionnement normalement organis\u00e9 de mani\u00e8re \u00e0 simplifier le travail du programmeur du scraper\n", "\n", "Mais aussi quelques inconv\u00e9niants :\n", "- Elles requi\u00e8rent g\u00e9n\u00e9ralement une forme d'authentification en tant qu'utilisateur et il faut donc effectuer la proc\u00e9dure d'enregistrement, certaines API requi\u00e8rent aussi des biblioth\u00e8ques Python suppl\u00e9mentaires\n", "- Elles sont g\u00e9n\u00e9ralement contraintes en termes de p\u00e9rim\u00e8tre : l'API peut \u00eatre organis\u00e9e de mani\u00e8re \u00e0 ne fournir qu'une partie des donn\u00e9es accessibles directement au travers du site web (ou n'\u00eatre accessible qu'en \u00e9change d'un paiement)\n", "- Elles sont g\u00e9n\u00e9ralement contraintes en termes de nombre de requ\u00eates par p\u00e9riode de temps (quoiqu'en hard-scraping on s'impose aussi volontairement des contraintes sur ce plan-l\u00e0)\n", "\n", "NB : les **API REST** (REpresentational State Transfer), parfois appel\u00e9es **RESTFul**, sont encore plus pratiques \u00e0 utiliser et ne n\u00e9cessitent g\u00e9n\u00e9ralement rien de plus que **requests**\n", "\n", "**Lorsque l'on scrape un site en utilisant une API, la phase d'analyse du site Web est remplac\u00e9e par une analyse de la documentation de l'API, peu importe la sturcture du site Web lui-m\u00eame.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Hard-scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Le **hard-scraping** est une activit\u00e9 qui consiste, malgr\u00e9 l'absence d'une structure de fourniture de donn\u00e9es organis\u00e9e de type API, \u00e0 obtenir des donn\u00e9es depuis un site web.\n", "\n", "En effet la **tr\u00e8s grande majorit\u00e9 des donn\u00e9es** qui s'affichent sur un navigateur web peuvent \u00eatre r\u00e9cup\u00e9r\u00e9es de mani\u00e8re automatis\u00e9e.\n", "\n", "En termes de l\u00e9galit\u00e9, c'est l\u00e0 que l'on est dans la **zone grise**, il faut se renseigner en lisant les conditions d'utilisation du site\n", "\n", "C'est une activit\u00e9 plus difficile \u00e0 mettre en oeuvre, et qui n'est pas document\u00e9e"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# R\u00e8gles du web scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Droit et \u00e9thique"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Attention : tout ce qui rel\u00e8ve du Hard-Scraping est, en termes de droit et \u00e0 l'heure actuelle (le droit est une mati\u00e8re en constante \u00e9volution), dans une zone que l'on pourrait qualifier de **zone grise**. De nombreux sites le pratiquent au quotidien, mais en l'\u00e9tat du droit fran\u00e7ais, **certaines de ces activit\u00e9s pourraient tomber sous le coup de la loi**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il est donc n\u00e9cessaire d'\u00eatre conscient du fait qu'il existe un risque potentiel \u00e0 pratiquer cette activit\u00e9."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Si vous agissez pour votre propre compte**, si par exemple vous montez une start-up dont l'objet commercial est centr\u00e9 sur le fruit de cette activit\u00e9, je vous recommande fortement de vous renseigner aupr\u00e8s d'une personne comp\u00e9tente dans le domaine du droit (avocat) avant de vous lancer."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Si vous agissez dans le cadre d'une relation de salariat**, c'est votre hi\u00e9rarchie, et en premier lieu le PDG qui a la responsabilit\u00e9 l\u00e9gale de vos activit\u00e9s, tant qu'il vous a \u00e9t\u00e9 demand\u00e9 effectivement de pratiquer ces activit\u00e9s. \n", "\n", "**Un conseil** : si vous n'\u00eates pas \u00e0 l'aise avec une activit\u00e9 qui vous est demand\u00e9e par un membre de votre hi\u00e9rarchie, faites-vous confirmer la demande par mail (et \u00e9ventuellement forwardez-vous la r\u00e9ponse vers votre bo\u00eete mail perso). Cela peut se faire sous la forme de l'expression d'un besoin de voir les choses \u00e9crites pour mieux savoir quoi faire ensuite."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dans le cas o\u00f9 vous choisiriez de faire un **projet de fin d'ann\u00e9e dans ce domaine**, les conditions de r\u00e9alisation de ce projet (le fait que vous n'avez aucun objectif commercial sur la base de ce projet, le cadre \u00e9ducatif, le fait que le web-scraping ne sera pas une fin en soi, mais le moyen d'obtenir des donn\u00e9es qui serviront l'objectif de votre projet, les faibles quantit\u00e9s de donn\u00e9es qui seront scrap\u00e9es, etc.) font que **vous n'avez aucune inqui\u00e9tude \u00e0 avoir**. En revanche, je vous demanderai alors de faire une section discutant bri\u00e8vement l'\u00e9tat du droit en la mati\u00e8re."]}, {"cell_type": "markdown", "metadata": {}, "source": ["A lire, un tr\u00e8s bon article r\u00e9cent sur l'\u00e9tat du droit en mati\u00e8re de hard-scraping :\n", "\n", "https://www.actualitesdudroit.fr/browse/tech-droit/start-up/9404/le-web-scraping-une-technique-d-extraction-legale"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Quoiqu'il en soit, il y a le droit, et il y a **l'\u00e9thique d'une pratique**, et d'ailleurs, dans le cadre d'un proc\u00e8s, les deux sont \u00e9valu\u00e9s. Je vous apprendrai dans ce cours \u00e0 agir de mani\u00e8re responsable, et \u00e0 **respecter** les sites que vous scraperez, et les entreprises et personnes derri\u00e8re ces sites. On peut pratiquer le scraping de mani\u00e8re respectueuse et non dommageable pour les sites."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## En pratique"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En pratique, pour savoir ce qu'il est permis de scraper sur un site, il y a deux sources d'infos :\n", "- les **Conditions G\u00e9n\u00e9rales** qu'il faut chercher sur le site (en anglais, c'est g\u00e9n\u00e9ralement les **Terms & Conditions**). On peut utilement chercher sur Google :\n", "\n", "> {nom de domaine} terms conditions scraping (en anglais)\n", ">\n", "> {nom de domaine} conditions g\u00e9n\u00e9rales scraping (en fran\u00e7ais)\n", "\n", "- le fichier **robots.txt**, qui existe sur tout site normalement constitu\u00e9. Il est syst\u00e9matiquement situ\u00e9 \u00e0 l'adresse **http(s)://{nom de domaine}/robots.txt**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##### Le user-agent"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Les autorisations et interdictions sont fournies par User-agent. Dans le robots.txt, l'indication de User-agent est ensuite suivie d'une s\u00e9rie de Allow (autorisations) et Disallow (interdictions).\n", "\n", "L'indication\n", "\n", "```User-agent: *```\n", "\n", "signifie : pour tout les utilisateurs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nota Bene : le symbole \u00e9toile (**\\***) signifie \"**tout**\" en informatique"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##### Interdictions g\u00e9n\u00e9rales"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En g\u00e9n\u00e9ral les premi\u00e8res lignes indiquent l'\u00e9tat d'esprit g\u00e9n\u00e9ral du site vis-\u00e0-vis du scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pour parler de **tout le site**, on utilise le symbole /\n", "\n", "```Disallow: /``` \n", "\n", "signifie : le scraping est interdit sur l'ensemble du site (sauf indications suppl\u00e9mentaires)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pour parler de **rien**, on ne met aucune indication\n", "\n", "```Disallow:```\n", "\n", "siginifie : rien n'est interdit"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##### Interdictions partielles"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Souvent, il n'y a que certaines parties du site qui sont interdites (ou autoris\u00e9es).\n", "\n", "On indique alors les parties autoris\u00e9es ou interdites en indiquant le chemin de base de ces parties:\n", "\n", "```Disallow: /images/``` \n", "\n", "Indique que tous les \u00e9l\u00e9ments du dossier images ne doivent pas \u00eatre scrap\u00e9s"]}, {"cell_type": "markdown", "metadata": {}, "source": ["On peut aussi utiliser des * pour dire \"tout\":\n", "\n", "```Disallow: /title/tt*/mediaviewer``` \n", "\n", "Indique que tous les \u00e9l\u00e9ments du dossier \"/title/tt...../mediaviewer\" sont interdits (tt* signifie tout nom commen\u00e7ant par tt et finissant par quoique ce soit) "]}, {"cell_type": "markdown", "metadata": {}, "source": ["##### Autorisations"]}, {"cell_type": "markdown", "metadata": {}, "source": ["De m\u00eame qu'il y a des interdictions, le concepteur du site peut explicitement sp\u00e9cifier des autorisations avec l'instruction Allow:\n", "\n", "```Allow: /images/``` \n", "\n", "signifie que le dossier images peut lui \u00eatre scrap\u00e9"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##### Exemple"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://www.marinetraffic.com/robots.txt\n", "\n", "```\n", "User-agent: *\n", "Allow: /\n", "Disallow: /mob/\n", "Disallow: /upload/\n", "Disallow: /users/\n", "Disallow: /wiki/\n", "``` \n", "\n", "\n", "Signifie que tout bot peut scraper le site sauf les sous-dossiers mob, upload, users et wiki"]}, {"cell_type": "markdown", "metadata": {}, "source": ["http://www.u-pec.fr/robots.txt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://www.imdb.com/robots.txt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##### Autres indications"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Crawl-delay: n\n", "    - Indique le d\u00e9lai minimal n entre 2 requ\u00eates\n", "- Visit-time: hhmm-HHMM\n", "    - Indique que le scraper est autoris\u00e9 entre hh:mm and HH:MM UTC (attention : en France, nous sommes en UTC+1 en hiver et UTC+2 en \u00e9t\u00e9)\n", "- Request-rate: p/n\n", "    - Indique le nombre maximal de pages p par tranche de n secondes\n", "- Sitemap: http://domaine/sitemap.xml\n", "    - Pr\u00e9sente les cartes (au sens g\u00e9ographique) du site "]}, {"cell_type": "markdown", "metadata": {}, "source": ["<div class=\"alert alert-block alert-info\"><b>Pour aller plus loin :</b> <a href=https://en.wikipedia.org/wiki/Robots_exclusion_standard> L'article sur le codage du fichier robots.txt sur Wikipedia  </a></div>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Les outils du scraper sous Python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il y a 4 modules incontournables pour faire du scraping en Python :\n", "- **Requests** : Le module qui permet de communiquer avec un site web\n", "- **Beautiful Soup** : Le module qui permet d'exploiter le contenu d'une page web\n", "- **Scrapy** : Le framework du scraping sous Python\n", "- **Selenium** : Un \u00e9mulateur de navigateur web"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Les trois \u00e9tapes de l'\u00e9laboration d'un scraper"]}, {"cell_type": "markdown", "metadata": {}, "source": ["On peut sch\u00e9matiquement diviser le travail d'\u00e9laboration d'un scraper en trois grandes phases :\n", "- L'**analyse** fine du fonctionnement d'un site web (ou le cas \u00e9ch\u00e9ant de son API)\n", "- L'**exploration** des possibilit\u00e9s de communication avec le site web sous Python et les premiers essais\n", "- La **r\u00e9alisation** d'un code permettant d'automatiser la r\u00e9cup\u00e9ration de donn\u00e9es\n", "\n", "Ce sont les trois sections que nous allons traiter par la suite. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Comment \u00e9valuer la difficult\u00e9 pour scraper un site ?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["J'ai cr\u00e9e un petit syst\u00e8me simple pour \u00e9valuer la facilit\u00e9 \u00e0 scraper un site. Ce syst\u00e8me repose sur 5 difficult\u00e9s potentielles du web-scraping auxquelles sont assign\u00e9es des note de 0 \u00e0 2. On obtient ainsi un syst\u00e8me de notation sur 10, o\u00f9 10 indique un site extr\u00eamement facile \u00e0 scraper (une API REST serait dans ce cas l\u00e0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Identification"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La question de l'identification est essentielle, certain sites sont quasi-impossible \u00e0 scraper pour des raisons d'identification. De plus, il n'est pas recommand\u00e9 de scraper en utilisant une identification quelconque, pour des raisons \u00e9videntes..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["- 2 : Pas d'identification\n", "\n", "La plupart des sites cit\u00e9s ci-dessous\n", "\n", "- 1 : Sites utilisant des Cookies contenant une forme d'identification\n", "\n", "https://www.oui.sncf/\n", "\n", "- 0 : Identification avec compte\n", "\n", "Tous les sites o\u00f9 il faut s'inscrire avec un nom d'utilisateur et un mot de passe"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Requ\u00e8te"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Les requ\u00eates peuvent \u00eatre plus ou moins simples \u00e0 formuler."]}, {"cell_type": "markdown", "metadata": {}, "source": ["- 2 : Requ\u00eate \u00e9vidente o\u00f9 les param\u00e8tres demand\u00e9s sont \u00e9crits de mani\u00e8re intelligible dans l'url\n", "\n", "http://www.seloger.com, https://www.blablacar.fr\n", "\n", "- 1 : Liste de requ\u00eates \u00e0 obtenir ou constituer au pr\u00e9alable\n", "\n", "https://www.meilleursagents.com\n", "\n", "- 0 : Javascript et requ\u00eates complexes, crypt\u00e9es, \u00e0 \u00e9tapes, autres...\n", "\n", "https://www.oui.sncf/ (requ\u00eates \u00e0 \u00e9tapes, on passe par des pages interm\u00e9diaires pour arriver \u00e0 la r\u00e9ponse)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Localisation de la r\u00e9ponse"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Une fois obtenue la r\u00e9ponse, il faut trouver les donn\u00e9es dans cette r\u00e9ponse, ces donn\u00e9es sont g\u00e9n\u00e9ralement soit au format JSON, directement fournies (rarement) ou cach\u00e9es dans une page HTML (plus courant), soit il faut pr\u00e9lever les donn\u00e9es directement dans un HTML, ce qui est plus fastidieux"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- 2 : JSON directement envoy\u00e9 en r\u00e9ponse\n", "\n", "https://www.marinetraffic.com\n", "\n", "- 1 : JSON inclu dans le code HTML\n", "\n", "http://www.seloger.com\n", "\n", "- 0 : JSON cach\u00e9 et encod\u00e9, HTML, autre\n", "\n", "https://www.amazon.fr"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Format de la r\u00e9ponse"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Le format de la r\u00e9ponse est le probl\u00e8me qui se pose ensuite."]}, {"cell_type": "markdown", "metadata": {}, "source": ["- 2 : Apr\u00e8s la phase de localisation des donn\u00e9es de la r\u00e9ponse, on a un JSON, facile \u00e0 utiliser\n", "\n", "https://www.blablacar.fr, http://www.seloger.com, https://www.marinetraffic.com\n", "\n", "- 1 : La r\u00e9ponse est un HTML dont les sections contenant des donn\u00e9es d\u00e9sign\u00e9es par un identifiant\n", "\n", "https://www.amazon.fr, https://www.meilleursagents.com (page ville)\n", "\n", "- 0 : La r\u00e9ponse est un HTML difficile \u00e0 traiter, autre\n", "\n", "https://www.meilleursagents.com (page r\u00e9gion)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Post-traitement"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Le post-traitement est la derni\u00e8re phase du travail, celle consistant \u00e0 rendre les donn\u00e9es exploitables par pandas. Nous sommes revenu \u00e0 des sujets plus habituels (cf. cours pr\u00e9c\u00e9dent), et un peu plus \u00e9loign\u00e9es du web-scraping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- 2 : Aucun post-traitement n\u00e9cessaire (le r\u00e9sultat est un ensemble de donn\u00e9es proprement format\u00e9es)\n", "\n", "- 1 : Post-traitement de contenu identifi\u00e9 (besoin de formater des dates, nettoyage complexe de chaines de caract\u00e8res ou autre domaines d\u00e9j\u00e0 abord\u00e9s)\n", "\n", "- 0 : Complexe pour des types de donn\u00e9es n\u00e9cessitant un v\u00e9ritable savoir faire : texte brut, image, donn\u00e9es crypt\u00e9es..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Les parades des sites"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Il existe de nombreuses parades permettant \u00e0 certains sites pour se pr\u00e9munir contre le scraping.\n", "\n", "Le grand classique est le d\u00e9compte d'acc\u00e8s sur une IP : certains sites peuvent d\u00e9cider qu'une m\u00eame IP ne peut acc\u00e9der \u00e0 leur site plus de x fois (g\u00e9n\u00e9ralement x fois par p\u00e9riode de temps). Au bout de ces x fois, ils vous forcent \u00e0 vous enregistrer, o\u00f9 vous forcent \u00e0 remplir un captcha. Lorsque cela vous arrive, vous pouvez vous appercevoir que vous \u00eates bloqu\u00e9s en allant sur le site avec votre navigateur."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.1"}, "toc": {"base_numbering": 1, "nav_menu": {"height": "500px", "width": "252px"}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "765.98px", "left": "0px", "right": "1359px", "top": "110.994px", "width": "180px"}, "toc_section_display": "block", "toc_window_display": true}, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}, "nbformat": 4, "nbformat_minor": 2}